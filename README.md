GPU 矩阵乘法代码

本代码旨在通过 PyTorch 框架利用多张 GPU 设备高效地执行大规模矩阵乘法运算，同时保持 GPU 的高负载以达到极致性能。

功能描述

该代码实现了以下功能：

	•	多GPU并行计算：支持同时利用多张 GPU 进行矩阵乘法运算。
	•	高效资源占用：通过设置运行间隔和矩阵规模，充分利用 GPU 计算资源，维持高效率。
	•	参数化配置：通过命令行参数灵活调整矩阵大小、GPU 数量以及执行间隔等。

环境依赖

运行该代码需要以下环境：

	1.	Python 3.8 及以上
	2.	PyTorch 1.12 及以上
	3.	NVIDIA GPU 驱动程序和 CUDA 工具包
	4.	支持多 GPU 计算的系统

安装必要的 Python 库：

pip install torch

参数说明

代码支持以下命令行参数：

	•	--size：矩阵的维度大小（默认值：1400）。
	•	--gpus：使用的 GPU 数量（默认值：1）。
	•	--interval：矩阵乘法间隔时间（单位：秒，默认值：0.00001）。

例如：

python matrix_multiplication_gpus.py --size 1400 --gpus 2 --interval 0.00001

示例运行

运行以下命令，进行两个 1400x1400 矩阵的乘法运算，使用 2 张 GPU，间隔 0.00001 秒：

python matrix_multiplication_gpus.py --size 1400 --gpus 2 --interval 0.00001

输出示例：

使用 GPU: [0, 1]
矩阵维度: 1400x1400
每次计算间隔: 0.00001 秒
...
计算完成！

注意事项

	1.	确保环境中存在足够数量的 GPU，并正确安装 NVIDIA 驱动及 CUDA 工具包。
	2.	调整 --size 参数可能导致显存占用增加，请根据设备显存大小选择合适的矩阵规模。
	3.	--interval 参数控制计算间隔，值越小 GPU 利用率越高，但可能会导致系统其他任务响应变慢。

许可证

本代码基于 MIT 许可证开源，欢迎自由使用和修改。
